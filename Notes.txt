- Was hebt mich bzw. meine Implementierung von anderen Umsetzungen ab? Wo liegt der Vorteil? Was mache ich besser/anders
- Warum gibt es eine analoge Lösung für ein eigentliches digitales Problem (Stichwort: Kamera)? digital UI --> analog Kamera --> digital Code
Da es zu Zeitaufwendig wäre die Modifikation der Pins selbstsändig zu machen möglich aber alles sehr filigran und die Firma die diese Produziert macht es nicht von selber,
man bräuchte neue Baupläne und Centkosten mehr für Liebherr weshalb dieser Ansatzt von der Oberen ebene verneint wurde. Deshalb Kamera um Display zu übertragen
- Warum Opencv? Mir war es wichtig eine Breite schnittstelle an Programmiersprachen unc crossplatform compatibilität zu haben sollte man nicht immer auf Windows bleiben. Außerdem ist opencv Open source und besitzt eine breite community die lizenzfrei immer und in zukunft zur verfügung steht. Aiuch ist die Firma dahinter eine non profit organisation.

Probleme:
- Bilder also Snapshots der Kamera sind Tagsüber mit Beleuchtung der Deckenlampe super jedoch nachts einfach sehr schlecht Lösung?: Belichtung bzw. der delay der Kamera bei Snapshots automatisch anpassen aber wenn ja wie welche Faktoren fast unmöglich zu berücksichtigen nur Tag/nacht oder auch wolkig wie soll man das immer alles prüfen generalisieren eventuell mit einer geschlossenen Kiste? oder die Bilder immer gleich erstellen und diese dann durch Algorithmus autohelligkeit immer auf einen Sollwert regeln
- Fokusstörung da immer auf Hintergrund fokusiert und Video langlaufend snapshotten sind die Ergebnisse auch von madiger Qualität
- Farbspektrum analysieren der Pixel ohne Toleranz unmöglich da man denkt es ist schwarz aber am Ende ist keines genau also = 0 schwarz deswegen muss mit Toleranz gearbeitet werden das fast schwarz oder eben auf alle anderen Farben angewendet auch funktioniert.
- Welches Featurematcher algorithmus nehmen? Da vergleich der vielen mit besseren da kostenlos usw.. siehe Folien Chapter:3 Seite 71 und ab weiviel matches es denn als sicher gilt auswerten (siehe nächstes Problem)
- wieviele feature best matches sind oder werden benötigt um eine gute klassifizierung zu bieten? laut ChatGPT: Threshold-Adaption in der Praxis: Einige Studien argumentieren, dass die Anzahl der benötigten Übereinstimmungen abhängig von der Szene und den Anforderungen variiert. In kontrollierten Umgebungen wird oft ein höherer Schwellenwert (z. B. 50 oder mehr Übereinstimmungen) gefordert, um eine hohe Zuverlässigkeit sicherzustellen, da die Bilddaten weniger durch externe Störfaktoren beeinflusst werden​ aber siehe auch diese Papers: 1. https://elib.dlr.de/97889/1/brisk_rm.pdf  2. https://isprs-archives.copernicus.org/articles/XL-1/371/2014/isprsarchives-XL-1-371-2014.pdf
- ocr probiert und halt bei allem brauchen wir Bilder mit vernünftiger Qualität problem von oben
- probleme im dunkler umgebung zwar gut da gleich aber display wenn nicht voll gefüllt nicht erkennbar deswegen lösung: Initialisierung kalibrierung mit ungleich schwarz um display mit pixel zuerkennen. auch werden die shots nicht zum richtigen verhältnis getroffen deswegen werden die 4 eckpunkte analysiert und auf die maße gesheeard
- werte mit RGB Tests waren kompliziert und nicht immer einfach -- bessere und auch mathematische herleitung gibt HSV da Hue Bereiche klar definiert sind einfachere handhabung deshalb änderung. Ebenso viel robuster gegen Lichtverhältnisse und  Keine komplexen Vergleiche wie if r > b and g > b, sondern klare Hue-Grenzen. Siehe: https://www.researchgate.net/publication/228895050_HSV-based_Color_Texture_Image_Classification_using_Wavelet_Transform_and_Motif_Patterns
	Achtung bei HSV Farbkreis rot kommt am Anfang und am Ende deswegen braucht man dafür zwei definierte Zonen siehe Bild auf: https://wisotop.de/hsv-und-hsl-farbmodell.php und: Achtung: OpenCV speichert HSV mit H-Werten zwischen 0-179!
																																																				Das heißt:

																																																				0° – 10° wird zu 0 – 5 in OpenCV
																																																				350° – 360° wird zu 175 – 179 in OpenCV
- Wenn kein Display erkannt wird bei der kalibrierung welche ungleich schwarze pixel anzeigt da ja im dunkeln keine ecken wenn das display schwarz ist anzeigt bzw erkannt werden kann soll ein error zurück gegeben werden und anstelle eckpunkte dann spezifischer flag abgespeichert werden was dann zukünftige aufrufe dazu verleitet das ganze bild zu nehmen ohne rücksicht auf displays usw.. zb count color mit ganzen übergebenem Bild --> Mit Canny Kantenerkennung für rechteck (Polygonapproximation) waren die ergebnisse am besten. explizit nach Kanten (starken Helligkeitsübergängen) via cv.Canny, statt nach der größten hellen Fläche.

Meine Anforderungen:
- Modularer klar strukturierter Aufbau das jede Funktion auch eine eigene Methode hat die aufgerufen werden kann aber chronologisch gut funktioniert


Ablauf:
1. Einlesen eines Bildes mit flexibler Anpassung an Größe, Nähe und Neigung.
2. Erkennung und Extraktion des Displays (viereckige UI).
3. Analyse der Pixel pro Farbe und Histogramme pro Farbe.
4. OCR-Analyse, um Texte zu erkennen und zu prüfen, ob ein bestimmter Text vorhanden ist.
5. Prüfen, ob ein gegebenes Bild ein Teil des Bildschirms ist und an der richtigen Position erkannt wird.

Inhaltlich Paper:
- Abstract
- Project explainen
- Technologien/ algorithmen warum und wie sie funktionieren
- Was hebt mein Projekt von anderen ab oder Use-Case erklären (Automation)
- Evaluierung



# Breite und Höhe des Bildes extrahieren (openCV)
height, width = gray_img.shape[:2]
# Breite (width) und Höhe (height) anzeigen
print(f"width: {width} Pixel")
print(f"height: {height} Pixel")



Robustheit:
- auf einem geht es aber ich auf vielen Bildern teste
- 
Paper:
- Was soll das 20.000 rote pixel aber wenn wir soll ich die nutzerausgabe machen also reicht ihnen die pixel 
- habe farbräume in 2 oder 3dimensionale raum wo ist der bereich der als rot bewertet wird, woanders würde das so nicht gehen zb autonomes fahren eventuell mathematisch aufschreiben wie ich das mathematisch recherchieren kann also klassifijation in 3 bereiche formuliert als formel je nach pixelwert
schreiben warum und wie man auf den weg gekommen ist den man nun macht.

in our pprior experience it wasnt successfull because of.. pixel classification auf dieses weges entschieden wir usn für das einfügen einer farbtolleranz 

Begründen warum ich diesen weg wählen

von wir sprechen.

Liebherr gespräch feedback:
echte Pixel mit Display vergleichen bzw. setzen

- returnwerte von einzelnen teile möglich
- ocr KI offline möglich?
- software packages lizensen prüfen
